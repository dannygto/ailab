import axios from 'axios';
import dotenv from 'dotenv';
dotenv.config();

// AIæ¨¡å‹é…ç½®æ¥å£
export interface AIModelConfig {
  id: string;
  name: string;
  provider: string;
  endpoint: string;
  apiKey?: string;
  available: boolean;
  maxTokens: number;
  temperature: number;
  description: string;
}

// èŠå¤©æ¶ˆæ¯æ¥å£
export interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string | Array<{
    type: 'text' | 'image_url';
    text?: string;
    image_url?: {
      url: string;
    };
  }>;
}

// AIå“åº”æ¥å£
export interface AIResponse {
  content: string;
  usage?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  model: string;
  finishReason?: string;
  reasoningContent?: string;
}

export class AIService {
  private models: Map<string, AIModelConfig> = new Map();

  constructor() {
    this.initializeModels();
  }

  private initializeModels() {
    // åªæ³¨å†Œä¸€ä¸ªè±†åŒ…æ¨¡å‹
    this.models.clear();
    const arkKey = process.env.ARK_API_KEY;
    this.models.set('doubao-seed-1-6-thinking-250615', {
      id: 'doubao-seed-1-6-thinking-250615',
      name: 'è±†åŒ… (ç«å±±æ–¹èˆŸ 1.6 Thinking)',
      provider: 'ç«å±±æ–¹èˆŸ',
      endpoint: 'https://ark.cn-beijing.volces.com/api/v3/chat/completions',
      apiKey: arkKey,
      available: !!arkKey && arkKey.length > 10,
      maxTokens: 16000,
      temperature: 0.7,
      description: 'å­—èŠ‚è·³åŠ¨è±†åŒ…å¤§æ¨¡å‹ 1.6 Thinkingï¼Œæ”¯æŒä¸­æ–‡å¯¹è¯å’Œå¤šæ¨¡æ€'
    });
    console.log('ã€AIServiceæ¨¡å‹æ³¨å†Œè¡¨ã€‘', Array.from(this.models.entries()));
    console.log('ã€AIServiceåˆå§‹åŒ–API Keyã€‘', arkKey);
  }

  // è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
  public getAvailableModels(): AIModelConfig[] {
    return Array.from(this.models.values()).filter(model => model.available);
  }

  // è·å–æŒ‡å®šæ¨¡å‹é…ç½®
  public getModelConfig(modelId: string): AIModelConfig | undefined {
    return this.models.get(modelId);
  }

  // ç«å±±æ–¹èˆŸAPIè°ƒç”¨
  private async callVolcanicArk(
    messages: ChatMessage[],
    config: AIModelConfig
  ): Promise<AIResponse> {
    try {
      console.log('ğŸ”¥ Ark API è¯·æ±‚å‚æ•°:', {
        url: config.endpoint,
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${config.apiKey}`
        },
        data: {
          model: 'doubao-seed-1-6-thinking-250615',
          messages: messages,
          max_tokens: config.maxTokens,
          temperature: config.temperature,
          stream: false
        }
      });
      const response = await axios.post(
        config.endpoint,
        {
          model: 'doubao-seed-1-6-thinking-250615',
          messages: messages,
          max_tokens: config.maxTokens,
          temperature: config.temperature,
          stream: false
        },
        {
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${config.apiKey}`
          },
          timeout: 60000
        }
      );

      const data = response.data;
      return {
        content: data.choices[0].message.content,
        usage: data.usage ? {
          promptTokens: data.usage.prompt_tokens,
          completionTokens: data.usage.completion_tokens,
          totalTokens: data.usage.total_tokens
        } : undefined,
        model: config.id,
        finishReason: data.choices[0].finish_reason
      };
    } catch (error: any) {
      console.error('ç«å±±æ–¹èˆŸAPIè°ƒç”¨å¤±è´¥:', error.response?.data || error.message);
      throw new Error(`ç«å±±æ–¹èˆŸAPIè°ƒç”¨å¤±è´¥: ${error.response?.data?.error?.message || error.message}`);
    }
  }

  // DeepSeek APIè°ƒç”¨
  private async callDeepSeek(
    messages: ChatMessage[],
    config: AIModelConfig
  ): Promise<AIResponse> {
    try {
      const response = await axios.post(
        config.endpoint,
        {
          model: config.id, // æ”¯æŒ deepseek-chat å’Œ deepseek-reasoner
          messages: messages,
          max_tokens: config.maxTokens,
          temperature: config.temperature,
          stream: false
        },
        {
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${config.apiKey}`
          },
          timeout: 60000 // è¶…æ—¶æ—¶é—´60ç§’
        }
      );
      const data = response.data;
      return {
        content: data.choices[0].message.content,
        usage: data.usage ? {
          promptTokens: data.usage.prompt_tokens,
          completionTokens: data.usage.completion_tokens,
          totalTokens: data.usage.total_tokens
        } : undefined,
        reasoningContent: data.choices[0].reasoning_content, // Reasoneræ¨¡å‹ç‰¹æœ‰
        model: config.id
      };
    } catch (error: any) {
      throw new Error('DeepSeek APIè°ƒç”¨å¤±è´¥: ' + (error.message || error.toString()));
    }
  }

  // ä¸»è¦èŠå¤©æ¥å£
  public async chat(
    messages: ChatMessage[],
    modelId: string = 'doubao-seed-1-6-thinking-250615',
    options?: {
      temperature?: number;
      maxTokens?: number;
      apiKey?: string;
    }
  ): Promise<AIResponse> {
    console.log('ã€AIService.chatè°ƒç”¨ã€‘', { modelId, models: Array.from(this.models.keys()), options });
    const model = this.getModelConfig(modelId);
    if (!model) {
      throw new Error(`æ¨¡å‹ ${modelId} ä¸å­˜åœ¨`);
    }

    // å¦‚æœæœ‰APIå¯†é’¥ï¼ŒåŠ¨æ€æ›´æ–°æ¨¡å‹é…ç½®
    if (options?.apiKey) {
      const updatedModel = { ...model, apiKey: options.apiKey, available: true };
      this.models.set(modelId, updatedModel);
      console.log(`ğŸ”‘ åŠ¨æ€æ›´æ–°æ¨¡å‹ ${modelId} çš„APIå¯†é’¥`);
    }

    if (!model.available && !options?.apiKey) {
      throw new Error(`æ¨¡å‹ ${modelId} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®`);
    }

    // åº”ç”¨é€‰é¡¹å‚æ•°
    const effectiveConfig = {
      ...model,
      temperature: options?.temperature ?? model.temperature,
      maxTokens: options?.maxTokens ?? model.maxTokens
    };

    // æ ¹æ®ä¸åŒæä¾›å•†è°ƒç”¨ç›¸åº”çš„API
    switch (model.provider) {
      case 'ç«å±±æ–¹èˆŸ':
        try {
          return await this.callVolcanicArk(messages, effectiveConfig);
        } catch (error) {
          throw new Error('ç«å±±æ–¹èˆŸAPIè°ƒç”¨å¤±è´¥');
        }
      case 'DeepSeek':
        try {
          return await this.callDeepSeek(messages, effectiveConfig);
        } catch (error) {
          throw new Error('DeepSeek APIè°ƒç”¨å¤±è´¥');
        }
      default:
        throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${model.provider}`);
    }
  }

  // æµ‹è¯•æ¨¡å‹è¿æ¥
  public async testModelConnection(modelId: string): Promise<{ success: boolean; message: string }> {
    try {
      const model = this.getModelConfig(modelId);
      
      if (!model) {
        return {
          success: false,
          message: `æ¨¡å‹ ${modelId} ä¸å­˜åœ¨`
        };
      }
      
      if (!model.available) {
        return {
          success: false,
          message: `æ¨¡å‹ ${modelId} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®`
        };
      }

      // æ„å»ºæµ‹è¯•æ¶ˆæ¯
      const testMessages: ChatMessage[] = [
        {
          role: 'user',
          content: 'ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ä¸€ä¸‹ç¡®è®¤è¿æ¥æ­£å¸¸ã€‚'
        }
      ];

      try {
        // å°è¯•è°ƒç”¨API
        const response = await this.chat(testMessages, modelId, { maxTokens: 50 });
        
        return {
          success: true,
          message: `æ¨¡å‹ ${modelId} è¿æ¥æˆåŠŸï¼Œå“åº”: ${response.content.substring(0, 50)}...`
        };
      } catch (error: any) {
        // å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œä½†æ¼”ç¤ºæ¨¡å¼å¯ç”¨
        throw new Error('æ¨¡å‹è¿æ¥å¤±è´¥');
      }
    } catch (error: any) {
      return {
        success: false,
        message: `æ¨¡å‹æµ‹è¯•å‡ºé”™: ${error.message}`
      };
    }
  }

  // æµ‹è¯•è¿æ¥ï¼ˆæ‰¹é‡æµ‹è¯•æ‰€æœ‰æ¨¡å‹ï¼‰
  public async testAllModels(): Promise<Record<string, { success: boolean; message: string }>> {
    const results: Record<string, { success: boolean; message: string }> = {};
    
    for (const [modelId] of this.models) {
      results[modelId] = await this.testModelConnection(modelId);
    }
    
    return results;
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const aiService = new AIService();
